{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech emotion recognization",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPb0MwIcRIB3a7/ZaUt5vs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonamSauntiyal/DAA-Lab-Assignment/blob/main/speech_emotion_recognization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ij84rszzpij"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sbn\n",
        "import matplotlib.pyplot as mplt\n",
        "import os,glob,pickle,sys\n",
        "import soundfile\n",
        "import librosa\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhaO_HTSylXn"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWZpWmOR1lIO"
      },
      "source": [
        "from IPython.display import Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaIHVcmH1250"
      },
      "source": [
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "lG7d-cYl2qYQ",
        "outputId": "25030344-023a-49d2-cb0a-cc7bbf65a24f"
      },
      "source": [
        "RavdessData=open(\"C:\\\\Users\\\\HP\\\\Documents\\\\Study material\\\\python\\\\ONGC PROJECT\\\\Data_Source\\\\Actor_*\\\\*.wav\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-46480f779915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRavdessData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\HP\\\\Documents\\\\Study material\\\\python\\\\ONGC PROJECT\\\\Data_Source\\\\Actor_*\\\\*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\HP\\\\Documents\\\\Study material\\\\python\\\\ONGC PROJECT\\\\Data_Source\\\\Actor_*\\\\*.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "j4TAca8uCJ7y",
        "outputId": "28966a53-1d6c-4453-c0f3-d2069e2c5ad6"
      },
      "source": [
        "ravdessDirectoryList=os.listdir(RavdessData)\n",
        "fileEmotion=[]\n",
        "filepath=[]\n",
        "for dir in glob.glob(\"C:\\\\Users\\\\HP\\\\Documents\\\\Study material\\\\python\\\\ONGC PROJECT\\\\Data_Source\\\\Actor_*\\\\*.wav\"):\n",
        "  actor=os.listdir(RavdessData+dir)\n",
        "  for file in actor:\n",
        "    part=file.split('.')[0]\n",
        "    part=part.split('-')\n",
        "    fileEmotion.append(int(part[2]))\n",
        "    filePath.append(RavdessData + dir + '/' + file)\n",
        "emotion_df=pd.dataframe(fileEmotion,coulmns=['Emotions'])\n",
        "path_df=pad.DataFrame(filePath,columns=['Path'])\n",
        "Ravdess_df=pad.concat([emotion_df,path],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b8a1341c3f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mravdessDirectoryList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRavdessData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfileEmotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\HP\\\\Documents\\\\Study material\\\\python\\\\ONGC PROJECT\\\\Data_Source\\\\Actor_*\\\\*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRavdessData\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\HP\\\\\\\\Documents\\\\\\\\Study material\\\\\\\\python\\\\\\\\ONGC PROJECT\\\\\\\\Data_Source\\\\\\\\Actor_*\\\\\\\\*.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCNSAHP8z2-O"
      },
      "source": [
        "def extract_feature(Data_Source,mfcc,chroma,mel):\n",
        "    with soundfile.Soundfile(Data_Source) as sound_file:\n",
        "        X=sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft=np.abs(librosa.stft(X))\n",
        "        result=np.array([])\n",
        "        if mfcc:\n",
        "            mfccs=np.mean(librosa.feature.mfcc(y=X,sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result,chroma))\n",
        "        if mel:\n",
        "            mel=np.mean(librosa.feature.melspectrogram(X,sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result,mel))\n",
        "    return result\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZpXgfUn0KBR"
      },
      "source": [
        "#dictionary of emotion \n",
        "emotions={\n",
        "        '01':'neutral',\n",
        "        '02':'calm',\n",
        "        '03':'happy',\n",
        "        '04':'sad',\n",
        "        '05':'angry',\n",
        "        '06':'fearful',\n",
        "        '07':'disgust',\n",
        "        '08':'surprised',\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yki1bXmh0dy0"
      },
      "source": [
        "#\n",
        "observed_emotions=['clam','happy','fearful','disgust']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KlTeEIj0j0N"
      },
      "source": [
        "#load the data and extract features for each sound file\n",
        "#C:\\Users\\HP\\Documents\\Study material\\python\\ONGC PROJECT\\Data_Source\n",
        "def load_data(test_size=0.2):\n",
        "        x,y=[],[]\n",
        "        for file in glob.glob(\"C:\\\\Users\\\\HP\\\\Documents\\\\Study material\\\\python\\\\ONGC PROJECT\\\\Data_Source\\\\Actor_*\\\\*.wav\"):\n",
        "            file_name=os.path.basename(file)\n",
        "            emotion=emtion[file_name.split(\"_\")[2]]\n",
        "            if emotion not in observed_emotions:\n",
        "                continue\n",
        "            feature=extract_feature(file,mfcc=True,chroma=True,mel=True)\n",
        "            x.append(feature)\n",
        "            y.append(emotion)\n",
        "        return train_test_split(np.array(x),y,test_size=test_size,random_state=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "C9-MItHP08qM",
        "outputId": "d8247ddb-a5cb-471e-f8e1-9a2503053716"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(np.array(x),y,test_size=0.25,random_state=9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-11fd358040d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#split the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    }
  ]
}